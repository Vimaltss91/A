import json

def update_json_with_text_data(text_file_path, json_file_path):
    try:
        # Read the contents of the text file
        with open(text_file_path, 'r') as text_file:
            text_data = text_file.read()

        # Load the existing JSON data
        with open(json_file_path, 'r') as json_file:
            json_data = json.load(json_file)

        # Convert text data to a dictionary
        text_dict = {}
        pairs = text_data.strip().split('\n')
        for pair in pairs:
            key, value = pair.split('=')
            text_dict[key.strip()] = value.strip()

        # Find the index of the dictionary in "data" list with matching job_id
        index_to_update = -1
        for idx, data_entry in enumerate(json_data["data"]):
            if data_entry.get("job_id") == text_dict.get("job_id"):
                index_to_update = idx
                break

        # Update the existing data with the new values for the matched job_id
        if index_to_update != -1:
            json_data["data"][index_to_update].update(text_dict)

        # Save the updated JSON data back to the file
        with open(json_file_path, 'w') as json_file:
            json.dump(json_data, json_file, indent=4)

        print("JSON file updated successfully.")
    except FileNotFoundError:
        print("File not found. Please check the file paths.")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    text_file_path = "path/to/your_text_file.txt"
    json_file_path = "path/to/your_json_file.json"
    update_json_with_text_data(text_file_path, json_file_path)

import os

def helm_check_version():
    cne_version = os.environ.get("CNE_VERSION", "")
    if "1.8" in cne_version:
        helm = "helm3"
    else:
        helm = "helm"
    return helm

helm = helm_check_version()
print(helm)


import subprocess
import os

def get_helm_list(namespace):
    try:
        helm_list_cmd = f"{helm} list -n {namespace}"
        output = subprocess.check_output(helm_list_cmd, shell=True, text=True)
        return output
    except subprocess.CalledProcessError as e:
        print(f"Error: {e}")
        return None

def get_release_tag(namespace):
    helm_output = get_helm_list(namespace)
    if helm_output:
        lines = helm_output.strip().split('\n')
        for line in lines:
            if namespace in line and 'csf' in line and 'ats' not in line and 'dns' not in line:
                parts = line.split()
                tag = parts[8].replace("ocbsf-", "")
                return tag
    return None

def main():
    CSF_SUITE = os.environ.get("CSF_SUITE", "")
    NAMESPACE = os.environ.get("NAMESPACE", "")
    helm = "helm"

    if CSF_SUITE == "CSF":
        RELEASE_TAG = get_release_tag(NAMESPACE)
        if RELEASE_TAG is None:
            RELEASE_TAG = "CSF_RELEASE_TAG"
    
    print(RELEASE_TAG)

if __name__ == "__main__":
    main()


def find_total_feature_with_previous_line(file_path):
    with open(file_path, "r") as file:
        previous_line = None
        for line in file:
            if "Total-Feature" in line and previous_line and "Final Result" in previous_line:
                return line.strip()  # Return the line containing "Total-Feature"
            previous_line = line  # Store the current line for the next iteration
    return None  # If not found, return None

file_path = "data.log"  # Replace with the actual file path

result_line = find_total_feature_with_previous_line(file_path)
if result_line:
    print(result_line)
else:
    print("Total-Feature with preceding 'Final Result' not found.")
In this Python code, the find_total_feature_with_previous_line function reads the file line by line. It checks for the presence of "Total-Feature" in the current line and also verifies if the previous line contains "Final Result." If both conditions are met, the function returns the line containing "Total-Feature" (stripped of leading/trailing spaces). Otherwise, it continues to the next line until the end of the file.

Replace "data.log" with the actual path to the file containing the log data. The variable result_line will contain the line with "Total-Feature" if it's found, and you will get the desired output. If the condition is not met, it will print "Total-Feature with preceding 'Final Result' not found."


# Open the file for reading
with open('your_file.txt', 'r') as file:
    lines = file.readlines()

# Initialize variables to store the extracted lines
start_index = None
end_index = None

# Find the indices of the lines that contain "Overall Result" and "Total-Features"
for i, line in enumerate(lines):
    if "Overall Result" in line:
        start_index = i
    if "Total-Features" in line:
        end_index = i
        break

# Extract the lines between the start and end indices
if start_index is not None and end_index is not None:
    extracted_lines = lines[start_index:end_index+1]
    for line in extracted_lines:
        print(line.strip())
else:
    print("Lines not found.")


#!/bin/bash

# Define the IP addresses or hostnames of the nodes
nodes=("node1" "node2" "node3")

# Define the content to append to /etc/hosts
content="100.100.100.100 mydomain.com"

# Loop through the nodes and perform the operation
for node in "${nodes[@]}"; do
    echo "Updating /etc/hosts on $node..."
    
    # Use SSH to append the content to /etc/hosts
    ssh -i /path/to/your/private/key.pem user@$node "echo '$content' | sudo tee -a /etc/hosts"
    
    echo "Update completed on $node."
done

echo "Script execution completed."


from datetime import datetime

def extract_time(line):
    parts = line.strip().split('=')
    return parts[0], parts[1]

def calculate_duration(start_time, end_time):
    start_datetime = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')
    end_datetime = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')
    duration = end_datetime - start_datetime
    return duration

# Read the log file
with open('sample.log', 'r') as log_file:
    lines = log_file.readlines()

# Extract relevant data
data = {}
for line in lines:
    key, value = extract_time(line)
    data[key] = value

# Calculate duration
if 'start_time' in data and 'end_time' in data:
    start_time = data['start_time']
    end_time = data['end_time']
    duration = calculate_duration(start_time, end_time)
    print(f"Start Time: {start_time}")
    print(f"End Time: {end_time}")
    print(f"Duration: {duration}")
else:
    print("Missing start_time or end_time in the log file.")

import re

def parse_time(time_str):
    hours = 0
    minutes = 0
    seconds = 0
    
    hours_match = re.search(r'(\d+)h', time_str)
    if hours_match:
        hours = int(hours_match.group(1))
    
    minutes_match = re.search(r'(\d+)m', time_str)
    if minutes_match:
        minutes = int(minutes_match.group(1))
    
    seconds_match = re.search(r'(\d+)s', time_str)
    if seconds_match:
        seconds = int(seconds_match.group(1))
    
    return hours, minutes, seconds

def add_times(time1, time2):
    hours1, minutes1, seconds1 = parse_time(time1)
    hours2, minutes2, seconds2 = parse_time(time2)
    
    total_hours = hours1 + hours2
    total_minutes = minutes1 + minutes2
    total_seconds = seconds1 + seconds2
    
    if total_seconds >= 60:
        total_minutes += total_seconds // 60
        total_seconds %= 60
    
    if total_minutes >= 60:
        total_hours += total_minutes // 60
        total_minutes %= 60
    
    return f"{total_hours}h {total_minutes}m {total_seconds}s"

regression_time = "1h0m1s"
new_feature_time = "12h30m2s"

total_time = add_times(regression_time, new_feature_time)
print("Total time:", total_time)


import re

def identify_branch(tag):
    match = re.match(r'^(\d{2}\.\d{1,2}\.\d{1,2})', tag)
    if match:
        version = match.group(1)
        last_digit = int(version.split('.')[-1])
        if last_digit == 0:
            if "-nb" in tag:
                branch = "dev"
            elif "beta.1" in tag:
                branch = "staging"
            elif "rc" in tag:
                branch = "master"
            else:
                branch = "master"
        else:
            branch = f"{version.split('.')[0]}.{version.split('.')[1]}.x-patch"
        return branch
    return "unknown"

# Example release tags
release_tags = [
    "23.3.0",
    "23.4.0",
    "23.3.0-nb.2023",
    "23.3.0-beta.1",
    "23.3.1",
    "23.3.2-beta.1",
    "23.4.1-rc.1",
    "invalid-tag"
]

for tag in release_tags:
    branch = identify_branch(tag)
    if branch == "unknown":
        print(f"Tag '{tag}' format is unknown.")
    else:
        print(f"Tag '{tag}' belongs to the '{branch}' branch.")


apiVersion: v1
kind: ServiceAccount
metadata:
  name: default
  namespace: <namespace>
imagePullSecrets:
  - name: your-docker-registry-secret


apiVersion: v1
kind: Pod
metadata:
  name: my-pod
  namespace: <namespace>
spec:
  containers:
    - name: my-container
      image: your-private-image:tag


import os
import requests

# GitLab API endpoint
api_url = "https://gitlab.com/api/v4/projects/{project_id}/jobs/{job_id}/retry"

# Personal Access Token
token = os.environ.get("GITLAB_TOKEN")

# Job details
project_id = os.environ.get("CI_PROJECT_ID")
job_id = os.environ.get("CI_JOB_ID")

# Retry the job using GitLab API
headers = {
    "PRIVATE-TOKEN": token
}
retry_url = api_url.format(project_id=project_id, job_id=job_id)
response = requests.post(retry_url, headers=headers)

if response.status_code == 201:
    print("Retry request successful")
else:
    print("Retry request failed")


trigger_retry:
  stage: test
  script:
    - python retry_script.py
  rules:
    - if: $CI_COMMIT_BRANCH =~ /^(dev|master|staging)$/
      when: on_failure


