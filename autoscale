#!/bin/bash

# Variables
namespace="your_namespace_value"  # Replace with your namespace value
ATS_link="your_ATS_link_value"    # Replace with your ATS link value

# MySQL command to update the ats_status and ats_link
mysql -u your_username -p'your_password' -h your_host -D your_database -e "
UPDATE namespace_status 
SET ats_status = 'Running', ats_link = '${ATS_link}'
WHERE namespace = '${namespace}';
"


New Tables
-----------------

CREATE TABLE namespace_status (
    s_no INT AUTO_INCREMENT PRIMARY KEY,
    nf_type VARCHAR(20),
    release_tag VARCHAR(30),
    ats_release_tag VARCHAR(30),
    namespace VARCHAR(50),
    is_csar ENUM('YES','NO') NOT NULL,
    is_asm ENUM('YES','NO') NOT NULL,
    is_tgz ENUM('YES','NO') NOT NULL,
    is_internal_ats ENUM('YES','NO') NOT NULL,
    is_occ ENUM('YES','NO') NOT NULL,
    is_pcf ENUM('YES','NO') NOT NULL,
	is_converged ENUM('YES','NO') NOT NULL,
    upg_rollback ENUM('YES','NO') NOT NULL,
    official_build ENUM('YES','NO') NOT NULL,
    priority ENUM('Critical','High','Medium','Low') NOT NULL,
    status VARCHAR(50),
    ats_status VARCHAR(50),
    ats_link VARCHAR(100),
    owner VARCHAR(50),
    pipeline VARCHAR(100),
    cpu_estimate VARCHAR(20),
    allocation_lock ENUM('YES','NO') NOT NULL,
    custom_message VARCHAR(200),
    deployment_Date TIMESTAMP,
    date TIMESTAMP DEFAULT CURRENT_TIMESTAMP 
);


INSERT INTO namespace_status (nf_type, release_tag,ats_release_tag, namespace, is_csar, is_asm, is_tgz, is_internal_ats, is_occ, is_pcf, is_converged, upg_rollback , official_build, priority , status, ats_status, ats_link, owner, pipeline, cpu_estimate, allocation_lock) VALUES
('policy','24.3.0-OCNGF-34343','24.3.0-OCNGF-34343', '', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'NO','YES', 'High','YET TO ASSIGN','','','vimal','','60'  ,'NO','@vsanthar @edugar fyi for the debug message','' );

INSERT INTO namespace_status (
    nf_type,
    release_tag,
    ats_release_tag,
    namespace,
    is_csar,
    is_asm,
    is_tgz,
    is_internal_ats,
    is_occ,
    is_pcf,
    is_converged,
    upg_rollback,
    official_build,
    priority,
    status,
    ats_status,
    ats_link,
    owner,
    pipeline,
    cpu_estimate,
    allocation_lock,
    custom_message,
    deployment_Date
) VALUES
(
    'bsf',
    '23.4.0-ocngf-4342',
    '23.4.0-ocngf-4342',
    '',
    'YES',
    'NO',
    'YES',
    'NO',
    'YES',
    'NO',
    'YES',
    'NO',
    'YES',
    'High',
    '',
    '',
    '',
    'Alice',
    '',
    '2',
    'NO',
    '@vsanthar @edugar fyi for the debug message',
    NULL
);




import requests
import json

def fetch_cpu_requests(prometheus_url):
    """
    Fetches CPU requests data from Prometheus.

    Parameters:
    prometheus_url (str): The URL of the Prometheus server.

    Returns:
    dict: The JSON response from Prometheus containing the query results.
    """

    # Prometheus query for CPU requests
    query = 'sum(kube_pod_container_resource_requests_cpu_cores) by (namespace, pod, container)'

    # Define the URL for the query API
    api_url = f"{prometheus_url}/api/v1/query"

    # Parameters to be sent to the API
    params = {
        'query': query
    }

    try:
        # Send the HTTP GET request
        response = requests.get(api_url, params=params)

        # Raise an exception for HTTP errors
        response.raise_for_status()

        # Parse the JSON response
        data = response.json()

        # Check for Prometheus API errors
        if data.get('status') != 'success':
            print("Error in Prometheus query:", data.get('error'))
            return None

        # Return the data part of the response
        return data['data']['result']

    except requests.exceptions.RequestException as e:
        print(f"Error fetching data from Prometheus: {e}")
        return None

# Example usage
prometheus_url = 'http://localhost:9090'
cpu_requests_data = fetch_cpu_requests(prometheus_url)

if cpu_requests_data:
    print(json.dumps(cpu_requests_data, indent=4))
