import os
import requests
import paramiko
import subprocess
from zipfile import ZipFile

# Step 1: Download the DB package
def download_package(url, download_path):
    response = requests.get(url, stream=True)
    if response.status_code == 200:
        with open(download_path, 'wb') as file:
            for chunk in response.iter_content(1024):
                file.write(chunk)
        print(f"Downloaded {download_path}")
    else:
        print("Failed to download package.")

# Step 2(i): Push the package to a different location in Artifactory
def upload_package_to_artifactory(file_path, upload_url, username, api_key):
    with open(file_path, 'rb') as file:
        response = requests.put(upload_url, auth=(username, api_key), data=file)
        if response.status_code == 201:
            print("Uploaded package to Artifactory successfully.")
        else:
            print("Failed to upload package to Artifactory.")

# Step 2(ii) & 2(iii): SCP the package to VMs
def scp_package_to_vm(file_path, vm_ip, vm_path, username='root', password='root'):
    ssh = paramiko.SSHClient()
    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    ssh.connect(vm_ip, username=username, password=password)

    # Create the target directory and set permissions
    stdin, stdout, stderr = ssh.exec_command(f"mkdir -p {vm_path} && chmod 777 {vm_path}")
    stdout.channel.recv_exit_status()
    
    # SCP the file
    with paramiko.Transport((vm_ip, 22)) as transport:
        transport.connect(username=username, password=password)
        sftp = transport.open_sftp()
        sftp.put(file_path, os.path.join(vm_path, os.path.basename(file_path)))
        sftp.close()
    print(f"Package sent to {vm_ip}:{vm_path}")

# Step 3(i): Unzip and load Docker images
def load_docker_images(zip_path):
    with ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall('/tmp/db_package')
    image_path = '/tmp/db_package/Artifacts/Images'
    for image_file in os.listdir(image_path):
        if image_file.endswith('.tar'):
            file_path = os.path.join(image_path, image_file)
            subprocess.run(['docker', 'load', '-i', file_path])

# Step 3(ii): Tag and push Docker images
def tag_and_push_images():
    # List all loaded images
    result = subprocess.run(['docker', 'images', '--format', '{{.Repository}}:{{.Tag}}'], capture_output=True, text=True)
    images = result.stdout.splitlines()
    
    for image in images:
        new_tag = f"cgbu-docker-dev/db/{image.split('/')[-1]}"
        subprocess.run(['docker', 'tag', image, new_tag])
        subprocess.run(['docker', 'push', new_tag])
        print(f"Tagged and pushed {new_tag}")

# Define main function
def main():
    package_url = "https://artifactoryhub.com/artifactory/db/24.3.0/24.3.0.zip"
    local_path = "/home/24.3.0.zip"
    artifactory_url = "https://artifactoryhub.com/artifactory/dbtier/24.3.0/24.3.0.zip"
    artifactory_user = "mail@APIKEY"
    artifactory_api_key = "YOUR_API_KEY"

    # Step 1
    download_package(package_url, local_path)

    # Step 2
    upload_package_to_artifactory(local_path, artifactory_url, artifactory_user, artifactory_api_key)
    
    # SCP to VMs
    vm1_path = "/var/www/html/builds/DBtier/24.3.0"
    vm2_path = "/var/www/html/builds/DBtier/24.3.0"
    scp_package_to_vm(local_path, '10.10.10.10', vm1_path)
    scp_package_to_vm(local_path, '10.10.10.11', vm2_path)

    # Step 3
    load_docker_images(local_path)
    tag_and_push_images()

if __name__ == "__main__":
    main()
