jq '.data | reverse | map(select(.city | contains("madurai")))[:2]' your_file.json
jq '.data | map(select(.city | contains("madurai"))) | reverse | .[:2]' your_file.json



kubectl patch deployment <deployment-name> -p '{"spec":{"template":{"metadata":{"annotations":{"safe-to-evict":null}}}}}'

#!/bin/bash

deployments=("deploy1" "deploy2" "deploy3")

for deployment in "${deployments[@]}"; do
  # Check if the deployment exists before attempting to patch
  if kubectl get deployment "$deployment" &> /dev/null; then
    kubectl patch deployment "$deployment" -p '{"spec":{"template":{"metadata":{"annotations":{"cluster-autoscaler.kubernetes.io/safe-to-evict":"false"}}}}}'
    echo "Deployment $deployment patched successfully."
  else
    echo "Deployment $deployment not found. Skipping patch."
  fi
done


#!/bin/bash

namespace="your-namespace"

deployments=$(kubectl get deployments -n "$namespace" -o jsonpath='{.items[*].metadata.name}')

for deployment in $deployments; do
    if [[ $deployment == *"$namespace"* ]]; then
        cat <<EOF | kubectl apply -f -
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: vpa-$deployment
  namespace: $namespace
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: $deployment
  updatePolicy:
    updateMode: "Auto"
EOF
        echo "VPA applied to $deployment"
    else
        echo "Skipping $deployment as it doesn't contain $namespace in the name"
    fi
done

apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: my-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind:       "Deployment"
    name:       "my-deployment"
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu:    100m
        memory: 128Mi
      maxAllowed:
        cpu:    0
        memory: 0
        
       
kubectl get pods --namespace <namespace> -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{range .spec.containers[*]}{.name}{"\t"}{.resources.requests.cpu}{"\t"}{.resources.limits.cpu}{"\n"}{end}{"\n"}{end}'

kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, allocatable_pods: .status.allocatable.pods, total_pods: .status.capacity.pods}'

kubectl get nodes -o custom-columns=NAME:.metadata.name,PODS:.status.capacity.pods,ALLOCATED:.status.allocatable.pods

kubectl get pods -o=jsonpath='{range .items[*]}{.spec.nodeName}:{.status.phase}{"\n"}{end}' | awk '{count[$1]++} END {for (i in count) print i, count[i]}'


NAMESPACE="your-namespace"
KEY="key-to-tolerate"
VALUE="value-to-tolerate"
OPERATOR="Equal"
EFFECT="NoSchedule"

PODS=$(kubectl get pods -n $NAMESPACE -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}')

for POD in $PODS; do
  TMP_FILE=$(mktemp)
  kubectl get pod $POD -n $NAMESPACE -o yaml > $TMP_FILE

  # Add toleration to each container in the pod
  CONTAINERS=$(kubectl get pod $POD -n $NAMESPACE -o jsonpath='{range .spec.containers[*]}{.name}{" "}{end}')
  for CONTAINER in $CONTAINERS; do
    kubectl patch pod $POD -n $NAMESPACE --type=json -p \
      "[{ \"op\": \"add\", \"path\": \"/spec/containers?(@.name=='$CONTAINER')/tolerations\", \"value\": [{ \"key\": \"$KEY\", \"operator\": \"$OPERATOR\", \"value\": \"$VALUE\", \"effect\": \"$EFFECT\" }] }]"
  done

  rm $TMP_FILE
done


NAMESPACE="your-namespace"
LABEL_KEY="key"
LABEL_VALUE="value"

PODS=$(kubectl get pods -n $NAMESPACE -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}')

for POD in $PODS; do
  TMP_FILE=$(mktemp)
  kubectl get pod $POD -n $NAMESPACE -o yaml > $TMP_FILE

  # Add node selector to the pod's YAML definition
  kubectl patch pod $POD -n $NAMESPACE --type='json' -p \
    "[{\"op\": \"add\", \"path\": \"/spec/nodeSelector\", \"value\": {\"$LABEL_KEY\": \"$LABEL_VALUE\"}}]"

  rm $TMP_FILE
done



#!/bin/bash

LABEL_KEY="key"
LABEL_VALUE="value"

DEPLOYMENTS=$(kubectl get deployments -o json | jq -r '.items[].metadata.name')

for DEPLOYMENT in $DEPLOYMENTS; do
  TMP_FILE=$(mktemp)
  kubectl get deployment $DEPLOYMENT -o yaml > $TMP_FILE

  # Add nodeSelector to the Deployment YAML
  sed -i "s/template:/template:\n    spec:\n      nodeSelector:\n        $LABEL_KEY: $LABEL_VALUE/g" $TMP_FILE

  # Apply the changes to the Deployment
  kubectl apply -f $TMP_FILE

  rm $TMP_FILE
done


#!/bin/bash

NODE_SELECTOR="key=value"

DEPLOYMENTS=$(kubectl get deployments -o json | jq -r '.items[].metadata.name')

for DEPLOYMENT in $DEPLOYMENTS; do
  kubectl patch deployment $DEPLOYMENT --type=json -p \
    "[{ \"op\": \"add\", \"path\": \"/spec/template/spec/nodeSelector\", \"value\": { \"$NODE_SELECTOR\" } }]"
done


sed -i 's/\(^\s*request:\)\s*$/\1\n\2    cpu: <new-cpu-value>\n\2    memory: <new-memory-value>/' file.yaml

sed -i '/<word>/,+2 {/<word>/!b;d;}' file.txt

my_array=("element1" "element2" "element3")

# Iterate over the array elements
for element in "${my_array[@]}"; do
    echo "$element"
done

current_date=$(date +%Y-%m-%d)
jq --arg current_date "$current_date" '.data[] | select(.["time-created"] | contains($current_date))' <your_json_file>

jq --arg current_date "$current_date" '.data[] | select((.["lifecycle-state"] == "test") and (.["time-created"] | contains($current_date)))' <your_json_file>

jq --arg current_date "$current_date" '.data[] | select((.["lifecycle-state"] == "test") and (.["time-created"] | contains($current_date) | not))' <your_json_file>


find /path/to/search -type f -name "*.yaml" -exec sed -i 's/word_to_replace/replacement_word/g' {} +


current_date=$(date -d "$(date +%Y-%m-%d) 00:00:00" +%s)
two_days_ago=$(date -d "-2 days" +%s)

while IFS= read -r line; do
  namespace=$(echo "$line" | awk '{print $1}')
  creation_date=$(kubectl get namespace "$namespace" -o jsonpath='{.metadata.creationTimestamp}')
  creation_date=$(date -d "$creation_date" +%s)

  if [[ $creation_date -ge $two_days_ago && $creation_date -lt $current_date ]]; then
    namespace_to_delete="$namespace"
    break
  fi
done < <(kubectl get namespaces --no-headers)


if [[ -n $namespace_to_delete ]]; then
  kubectl delete namespace "$namespace_to_delete"
  echo "Namespace '$namespace_to_delete' deleted."
else
  echo "No namespace found that matches the specified criteria."
fi


# Define an array with values
my_array=("value1" "value2" "value3")

# Value to check
value_to_check="value2"

# Flag to indicate if the value is found
found=false

# Iterate over each element in the array
for element in "${my_array[@]}"
do
  # Compare the element with the value to check
  if [[ "$element" == "$value_to_check" ]]; then
    found=true
    break
  fi
done

# Check if the value was found or not
if [[ $found == true ]]; then
  echo "The value '$value_to_check' is present in the array."
else
  echo "The value '$value_to_check' is not present in the array."
fi


100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

sum(rate(container_cpu_usage_seconds_total{container_name!="POD", container_name!="", image!="", pod_name!=""}[1m])) by (instance) / count(node_cpu_seconds_total{mode="system"}) * 100


#!/bin/bash

url="YOUR_URL_HERE"
loop_duration=300 # 5 minutes in seconds
wait_interval=30   # 30 seconds

# Loop for 5 minutes
end_time=$((SECONDS + loop_duration))
while [ $SECONDS -lt $end_time ]; do
    response=$(curl -s -o /dev/null -w "%{http_code}" "$url")
    if [ "$response" -eq 200 ]; then
        echo "200 OK received"
        sleep $wait_interval
        echo "Running echo command"
        break
    else
        echo "Response was not 200 OK (HTTP $response)"
        sleep 5  # Wait for 5 seconds before trying again
    fi
done

docker exec CONTAINER_ID_OR_NAME curl -s -o /dev/null -w "%{http_code}" "http://localhost:CONTAINER_PORT/ENDPOINT_PATH"

kubectl get namespaces -o=jsonpath='{range .items[*]}{"\nNamespace: "}{.metadata.name}{"\nCPU Request: "}{.spec[''resourceQuotas''][''requests.cpu'']}{"\n"}{end}'


import json

def convert_text_to_json(text_file_path, json_file_path):
    try:
        # Read the contents of the text file
        with open(text_file_path, 'r') as text_file:
            text_data = text_file.read()

        # Split the text into lines
        lines = text_data.strip().split('\n')

        # Create an empty dictionary to store the data
        data = {}

        # Process each line and add the key-value pairs to the dictionary
        for line in lines:
            key, value = line.strip().split('=')
            data[key] = value

        # Save the data as JSON
        with open(json_file_path, 'w') as json_file:
            json.dump(data, json_file, indent=4)

        print("Text data converted to JSON successfully.")
    except FileNotFoundError:
        print("File not found. Please check the file paths.")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    text_file_path = "path/to/your_text_file.txt"
    json_file_path = "path/to/your_json_file.json"
    convert_text_to_json(text_file_path, json_file_path)


import json

def append_text_to_json(text_file_path, json_file_path):
    try:
        # Read the contents of the text file
        with open(text_file_path, 'r') as text_file:
            text_data = text_file.read()

        # Load the existing JSON data if the file exists
        if not os.path.exists(json_file_path):
            json_data = {}
        else:
            with open(json_file_path, 'r') as json_file:
                json_data = json.load(json_file)

        # Convert text data to a dictionary
        text_dict = {}
        pairs = text_data.strip().split()
        for pair in pairs:
            key, value = pair.split('=')
            text_dict[key] = value

        # Update the existing JSON data with the new text data
        json_data.update(text_dict)

        # Save the updated JSON data back to the file
        with open(json_file_path, 'w') as json_file:
            json.dump(json_data, json_file, indent=4)

        print("Text data appended to the JSON file successfully.")
    except FileNotFoundError:
        print("File not found. Please check the file paths.")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    import os

    text_file_path = "path/to/your_text_file.txt"
    json_file_path = "path/to/your_json_file.json"
    append_text_to_json(text_file_path, json_file_path)


import json

def append_text_to_json(text_file_path, json_file_path):
    try:
        # Read the contents of the text file
        with open(text_file_path, 'r') as text_file:
            text_data = text_file.read()

        # Load the existing JSON data
        with open(json_file_path, 'r') as json_file:
            json_data = json.load(json_file)

        # Convert text data to a dictionary
        text_dict = {}
        pairs = text_data.strip().split('\n')
        for pair in pairs:
            key, value = pair.split('=')
            text_dict[key.strip()] = value.strip()

        # Append the new data to the existing "data" key in the JSON
        json_data["data"].append(text_dict)

        # Save the updated JSON data back to the file
        with open(json_file_path, 'w') as json_file:
            json.dump(json_data, json_file, indent=4)

        print("Text data appended to the JSON file successfully.")
    except FileNotFoundError:
        print("File not found. Please check the file paths.")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    text_file_path = "path/to/your_text_file.txt"
    json_file_path = "path/to/your_json_file.json"
    append_text_to_json(text_file_path, json_file_path)


echo "Took 0h29m Initial Run:- Features RUN 7, PASS 6, FAIL 1 1st ReRun:- Features RUN 7, PASS 6, FAIL 1 Final Result:- Total-Features RUN 7, PASS 7, FAIL 0.." | grep -oP '(?<=FAIL )\d+' | tail -1

def build_type(release_tag):
    if "nb" in release_tag:
        BUILD_TYPE = "NIGHTLY"
        BUILD_BRANCH = "DEV"
    elif "rc" in release_tag:
        BUILD_TYPE = "RC_BUILD"
        BUILD_BRANCH = "Staging"
    else:
        BUILD_TYPE = "GA"
        BUILD_BRANCH = "Master"
    
    return BUILD_TYPE, BUILD_BRANCH


def update_or_add_key_value(filename, input_string):
    if '=' in input_string:
        key, value = input_string.split('=')

        data = {}

        # Read existing data from the file
        try:
            with open(filename, 'r') as file:
                for line in file:
                    line = line.strip()
                    if '=' in line:
                        k, v = line.split('=', 1)
                        data[k.strip()] = v.strip()
        except FileNotFoundError:
            pass  # File doesn't exist yet, which is okay

        # Update or add the key-value pair
        data[key] = value

        # Write the updated data back to the file
        with open(filename, 'w') as file:
            for k, v in data.items():
                file.write(f"{k}={v}\n")

if __name__ == "__main__":
    filename = "data.txt"
    input_string = input("Enter the key-value pair (key=value): ")


import re

def validate_tag(tag):
    pattern = r'^\d{2}\.\d\.\d$'
    return re.match(pattern, tag) is not None

# Test cases
valid_tags = ["23.3.0", "24.3.1", "23.2.0-ocngf"]
invalid_tags = ["23.a.0", "24.3.1.5", "10.10.10"]

for tag in valid_tags:
    if validate_tag(tag):
        print(f"{tag} is a valid tag.")
    else:
        print(f"{tag} is NOT a valid tag.")

for tag in invalid_tags:
    if validate_tag(tag):
        print(f"{tag} is a valid tag.")
    else:
        print(f"{tag} is NOT a valid tag.")

    update_or_add_key_value(filename, input_string)
    print("Data has been updated or added.")


# List of remote servers
remote_hosts=("remote_host1" "remote_host2" "remote_host3")

# Common details
remote_user="your_normal_user"
local_path="/path/to/source/file"
destination_path="/path/to/destination/location"

# Loop through the remote hosts
for remote_host in "${remote_hosts[@]}"; do
    # Copy file as a normal user to /tmp location on the remote server
    scp "$local_path" "$remote_user@$remote_host:/tmp/"

    # Move the file to a different location on the remote server using sudo
    ssh "$remote_user@$remote_host" "sudo mv /tmp/$(basename $local_path) $destination_path/"
done


GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, INDEX, LOCK TABLES, REFERENCES, CREATE TEMPORARY TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON your_database.* TO 'your_user'@'your_host';

#!/bin/bash

# Set your Slack OAuth token
SLACK_TOKEN="YOUR_OAUTH_TOKEN"

# Set the Slack channel where you want to send the notification
CHANNEL="#your_channel"

# Set the message you want to send
MESSAGE="Hello, this is a test message from your Bash script!"

# Slack API URL for chat.postMessage
SLACK_API_URL="https://slack.com/api/chat.postMessage"

# Make the API request using curl
curl -X POST -H "Content-type: application/json" \
     -H "Authorization: Bearer $SLACK_TOKEN" \
     --data "{
       \"channel\": \"$CHANNEL\",
       \"text\": \"$MESSAGE\"
     }" $SLACK_API_URL
