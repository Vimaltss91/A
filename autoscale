def fetch_total_cpu_requests_with_validation(cursor, current_build_priority):
    """
    Fetches total CPU requests from Prometheus and validates it against certain thresholds.
    Returns the total CPU requests if it passes validation, otherwise None.
    """

    # prometheus_url = get_prometheus_url_from_db(cursor)
    #
    # if not prometheus_url or not check_prometheus_url_reachable(prometheus_url):
    #     logging.error("Failed to retrieve or reach Prometheus URL.")
    #     return None
    while True:
        try:
            # Fetch total CPU requests from user
            total_cpu_requests = get_total_cpu_requests_from_user()
            if total_cpu_requests is None:
                logging.error("Failed to fetch total CPU requests. Exiting validation loop.")
                return None

            # Check if total CPU requests are within the acceptable limit
            if total_cpu_requests > config.CPU_LIMIT_HIGH:
                logging.warning(f"Total CPU requests ({total_cpu_requests}) exceeded limit ({config.CPU_LIMIT_HIGH}). Waiting for {config.SLEEP_DURATION / 60} minutes before rechecking...")
                time.sleep(config.SLEEP_DURATION)
                continue

            # Start a transaction to ensure data consistency
            cursor.execute("START TRANSACTION;")

            # Fetch the sum of estimated CPU from the database
            sum_estimate_cpu = fetch_sum_estimate_cpu(cursor)
            if total_cpu_requests + sum_estimate_cpu > config.CPU_LIMIT_HIGH:
                logging.info(f"Combined CPU Requests: {total_cpu_requests + sum_estimate_cpu} exceeds limit {config.CPU_LIMIT_HIGH}. Waiting...")
                cursor.execute("ROLLBACK;")
                time.sleep(config.SLEEP_DURATION)
                continue

            # Check priority conditions if any
            priority_condition_check = check_priority_condition(cursor, current_build_priority)
            if priority_condition_check:
                priority_job_estimate_cpu = fetch_priority_job_estimate_cpu(cursor, get_priorities_to_check(current_build_priority))
                if total_cpu_requests + sum_estimate_cpu + priority_job_estimate_cpu > config.CPU_LIMIT_HIGH:
                    logging.warning(f"Combined CPU requests exceed {config.CPU_LIMIT_HIGH} cores and higher priority jobs exist. Waiting...")
                    cursor.execute("ROLLBACK;")
                    time.sleep(config.SLEEP_DURATION)
                    continue

            # If all conditions are satisfied, commit the transaction and return the total CPU requests
            cursor.execute("COMMIT;")
            logging.info("CPU requests are within limits. Proceeding with allocation.")
            return total_cpu_requests

        except Exception as e:
            cursor.execute("ROLLBACK;")  # Rollback on error
            logging.error(f"Error while validating total CPU requests: {e}")
            time.sleep(config.SLEEP_DURATION)  # Sleep before retrying


def find_and_lock_available_namespace(cursor, nf_type: str) -> Optional[str]:
    """
    Tries to find and lock an available namespace for allocation, with retries and waiting.
    """
    namespace_prefix = get_namespace_prefix(nf_type)
    if not namespace_prefix:
        return None

    while True:
        try:
            cursor.execute("START TRANSACTION;")  # Start transaction

            query = """
                SELECT namespace FROM namespace
                WHERE status = 'Available' AND allocation_lock = 'NO'
                  AND namespace LIKE %s
                LIMIT 1
            """
            params = (f'{namespace_prefix}%',)
            execute_query(cursor, query, params)
            available_namespace = cursor.fetchone()

            if available_namespace:
                namespace_name = available_namespace[0]

                # Lock the namespace
                lock_query = """
                    UPDATE namespace
                    SET allocation_lock = 'YES'
                    WHERE namespace = %s
                      AND allocation_lock = 'NO'
                """
                lock_params = (namespace_name,)
                cursor.execute(lock_query, lock_params)

                if cursor.rowcount == 1:  # Lock was successful
                    cursor.execute("COMMIT;")  # Commit the transaction
                    return namespace_name
                else:
                    # Lock failed, meaning it was locked by another process
                    cursor.execute("ROLLBACK;")  # Rollback the transaction
                    continue  # Retry

            else:
                cursor.execute("ROLLBACK;")  # Rollback the transaction
                logging.info(f"No available namespaces. Retrying in {config.SLEEP_DURATION} minutes...")
                time.sleep(config.SLEEP_DURATION)

        except Exception as e:
            cursor.execute("ROLLBACK;")  # Rollback on error
            logging.error(f"Error while finding and locking namespace: {e}")
            time.sleep(config.SLEEP_DURATION)  # Sleep before retrying


def find_and_lock_available_namespace(cursor, nf_type: str) -> Optional[str]:
    """
    Tries to find and lock an available namespace for allocation, with retries and waiting.
    """
    namespace_prefix = get_namespace_prefix(nf_type)
    if not namespace_prefix:
        return None

    while True:
        query = """
            SELECT namespace FROM namespace 
            WHERE status = 'Available' AND allocation_lock = 'NO' 
              AND namespace LIKE %s 
            LIMIT 1
        """
        params = (f'{namespace_prefix}%',)
        
        # Re-execute the query and check if a namespace is available
        try:
            cursor.execute(query, params)
            available_namespace = cursor.fetchone()
        except Exception as e:
            logging.error(f"Error executing query: {e}")
            return None

        if available_namespace:
            namespace_name = available_namespace[0]
            try:
                lock_namespace(cursor, namespace_name)  # Lock the namespace if found
                return namespace_name
            except Exception as e:
                logging.error(f"Error locking namespace {namespace_name}: {e}")
        else:
            logging.info(f"No available namespaces. Retrying in {config.SLEEP_DURATION} minutes...")
            time.sleep(config.SLEEP_DURATION)
            # Optionally, reset cursor if required by your DB backend
            # cursor.reset() # Uncomment if needed for certain DBs


match = re.search(r"NAMESPACE update to '(\S+)'", content)

    # If a match is found, return the value; otherwise, return None
    if match:
        return match.group(1)
    else:
        return None

CREATE TABLE namespace_status (
    s_no INT AUTO_INCREMENT PRIMARY KEY,
    nf_type VARCHAR(20),
    release_tag VARCHAR(30),
    ats_release_tag VARCHAR(30),
    namespace VARCHAR(50),
    is_csar ENUM('YES','NO') NOT NULL,
    is_asm ENUM('YES','NO') NOT NULL,
    is_tgz ENUM('YES','NO') NOT NULL,
    is_internal_ats ENUM('YES','NO') NOT NULL,
    is_occ ENUM('YES','NO') NOT NULL,
    is_pcf ENUM('YES','NO') NOT NULL,
	is_converged ENUM('YES','NO') NOT NULL,
    is_pcrf ENUM('YES','NO') NOT NULL,
    upg_phase VARCHAR(30),
    play_id VARCHAR(30),
    tls_version VARCHAR(20),
    upg_rollback ENUM('YES','NO') NOT NULL,
    official_build ENUM('YES','NO') NOT NULL,
    priority ENUM('Critical','High','Medium','Low') NOT NULL,
    status VARCHAR(50),
    ats_status VARCHAR(50),
    ats_link VARCHAR(100),
    owner VARCHAR(50),
    pipeline VARCHAR(100),
    cpu_estimate VARCHAR(20),
    allocation_lock ENUM('YES','NO') NOT NULL,
    custom_message VARCHAR(200),
    deployment_Date TIMESTAMP,
    date TIMESTAMP DEFAULT CURRENT_TIMESTAMP 
);


import requests
import logging

def fetch_total_cpu_requests_from_prometheus(prometheus_url, timeout=10):
    """Fetches the total CPU requests from Prometheus."""
    # Extract the IP from the URL
    ip_address = prometheus_url.split("//")[1].split(":")[0]

    # Configure no_proxy directly in the request
    proxies = {
        "http": None,
        "https": None,
        "no_proxy": ip_address  # Add IP to bypass proxy for this specific request
    }

    query = 'sum(kube_pod_container_resource_requests{resource="cpu",node=~".*"})'
    api_url = f"{prometheus_url}/api/v1/query"
    params = {'query': query}

    try:
        response = requests.get(api_url, params=params, timeout=timeout, proxies=proxies)
        response.raise_for_status()
        data = response.json()

        if data.get('status') != 'success':
            logging.error(f"Error in Prometheus query: {data.get('error')}")
            return None

        result = data['data']['result']

        if result:
            total_cpu_request = float(result[0]['value'][1])
            logging.info(f"Fetched total CPU requests: {total_cpu_request} cores.")
            return total_cpu_request
        else:
            logging.warning("No data returned by Prometheus query.")
            return None

    except requests.exceptions.RequestException as e:
        logging.error(f"Error fetching data from Prometheus: {e}")
        return None
